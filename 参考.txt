一、所开发的核心业务模块、开发工具及选择理由说明
核心业务模块（后端：Spring Boot）
变化检测/任务处理模块：围绕“上传影像—创建检测任务—执行变化检测—输出结果（含对比/标注）—查询任务状态与结果”这一主流程组织接口与服务。
图像与文件管理模块：对上传的影像文件进行落盘管理（如 uploads/），并提供访问/查询能力；与任务结果文件（静态资源或结果图）形成关联。
数据持久化模块：使用 Repository/Entity/POJO 分层对任务、影像、结果等信息进行存储与查询，保障任务可追踪、可回溯。
Web 接口层（Controller）：提供前端调用的 REST API（例如检测控制器相关测试用例已存在），完成参数校验、任务触发、结果查询等。
核心业务模块（前端：forestry-frontend，Vue + Vite）
上传与影像管理：ImageUpload / ImageManager 等组件用于选择文件、上传、展示影像列表。
任务监控与结果查看：TaskMonitor / ResultViewer / TaskDetailPage 等用于展示任务进度、任务详情、结果图/差异图等。
页面路由与业务编排：router.js + views 负责将上传、检测、详情等页面串联起来，形成可操作闭环。
开发工具与选择理由
后端：Java + Spring Boot（配合 Maven）
理由：生态成熟、工程化能力强（配置、依赖管理、分层清晰）、适合快速搭建 REST 服务并便于后续扩展；Maven 便于依赖与构建的统一管理。
前端：Vue 3 + Vite
理由：组件化开发效率高；Vite 构建与热更新速度快，适合迭代 UI 与联调接口。
测试：JUnit 5 + SpringBootTest
理由：与 Spring Boot 集成紧密，可做上下文加载、Web 层/集成测试；便于在持续集成中自动执行。
版本与协作：Git（若项目已使用）
理由：便于多人协作、变更追踪、回滚与发布管理。
二、是否借助了 AI 生成代码；如是，工具与代码质量分析
若使用过：可填写“使用 GitHub Copilot / ChatGPT / 通义千问 / 文心一言等（按实际情况选择）辅助生成部分样板代码与接口草稿”。
对 AI 生成代码质量的分析（可直接写入报告）：
优点：
对样板代码（Controller/DTO/简单 CRUD、前端组件骨架、接口调用封装）生成速度快，能明显减少重复劳动。
对常见框架用法（Spring 注解、Vue 组件结构、异步请求封装）能给出可运行的“起步实现”。
风险/不足：
业务贴合度不足：AI 往往不了解你的数据模型与真实流程，生成的字段/接口路径/异常分支可能与项目不一致，需要人工对齐。
健壮性不足：对边界条件（空文件、超大文件、并发任务、失败重试、权限与路径安全）覆盖不全。
规范性不稳定：可能出现命名风格不统一、分层不清晰、重复逻辑、缺少注释或日志等问题。
结论（建议表述）：
AI 更适合“提速与提供参考实现”，关键业务逻辑、异常处理、安全与性能仍需人工审查、重构与补充测试后才能纳入主干。
三、是否借助 AI 进行测试；如是，工具与测试质量分析
若使用过：可填写“使用 GitHub Copilot / ChatGPT 等辅助生成测试用例思路、Mock 方案、测试数据构造与断言模板”。
对 AI 辅助测试质量的分析（可直接写入报告）：
优点：
能快速给出测试结构（JUnit5、SpringBootTest、MockMvc 基本用法）、测试分层建议（单元/集成/接口）。
对常见场景（接口成功/失败、参数校验、状态码与返回体断言）编写效率高。
风险/不足：
容易“只测通路”：AI 生成的用例常偏向 happy path，对异常链路、资源清理、并发一致性等覆盖不足。
对项目真实约束不了解：例如实际返回结构、状态机、文件 IO、副作用（落盘、数据库写入）可能未被正确隔离或断言。
需要人工补齐：测试数据应贴近真实数据集（例如 data/ 下的影像样例）、并加入失败场景与边界场景。
结论（建议表述）：
AI 可提升测试“起量速度”，但测试是否有效取决于人工定义的断言质量、场景覆盖、以及对业务不变量的检查；最终应以覆盖关键路径与回归稳定性为验收标准。